#### 按照代码框架填东西

+ data目录放置数据集，目录下数据集以目录形式存放，不要将train,dev,test数据文件直接放在data目录下，根据数据集的名称修改DATAROOT
+ models存放模型，各个子模型分文件写，最后主模型只须调用各个子模型即可
+ run存放sh脚本文件，在里面修改或添加参数，运行时在项目根目录下使用命令sh run.sh，可根据不同任务创建更多的sh文件
+ scripts存放sh脚本需要调用的训练与测试脚本，可根据不同任务模仿main.py的格式创建其他运行脚本，sh文件尽量与存放的脚本文件一一对应
+ utils中存放各种工具
  - preprocess中提供对数据集的预处理，例如分割训练集、整理数据集（将复杂的数据结构中的有用的东西整理成方便调用的结构，重新存储）等
  - 如果需要后处理可创建postprocess文件，在其中编写后处理所需要的工具函数
  - data_reader
    + 将每条数据封装在Data类中，将对单条数据的预处理函数定义在类中
    + 使用get_minibatch将数据集划分成若干个batch
    + 使用normalize_minibatch规格化每个batch，如要使用RNN时需要将一个batch中的数据重整打包之类的
    + 最终将整个数据的预处理过程都封装在DataLoader中，最后运行脚本中直接通过输入数据路径即可通过此函数得到input和output一起其他必要数据
    + 可根据需要添加函数
  - gpu_selection不用理会
  - loss_function中除了定义损失函数选择器还可定义一些torch中没有的损失函数
  - optim中定义优化器选择器
  - solver
    + Solver为一虚基类，每个任务需要调用的solver都应继承于Solver
    + 根据任务定义的solver中定义训练函数和测试函数
  - util中定义一些其他的使用工具，如一些预处理中需要用到的小工具都可以写在其中，还有就是根据每个模型的特有的参数需要写一个hyperparam_string来定义log的输出路径，方便观察结果这一函数将在训练脚本中被调用（见main.py）
  - 可根据其他需求创建更多的文件，文件的功能最好独立
